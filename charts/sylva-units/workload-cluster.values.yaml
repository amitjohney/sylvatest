# ############################################################################
#
# This Helm values files contains override used to create a workload cluster
# with sylva-units chart and deploy a selected subset of units into it.
#
# ############################################################################

# This value override file is meant to deploy sylva-units _in the mgmt cluster_
# _in a dedicated namespace_, it will produce Flux Kustomization and HelmReleases
# _in the mgmt cluster_ and those will ultimately deploy Kubernetes resources
# in the workload cluster itself.
#
# There are a few exceptions:
# - the 'cluster' unit produces CAPI resource for the cluster _in the mgmt cluster_

# when this values override file is used, it is assumed that
# - `cluster.name` contains the name of the workload cluster to work on
# - `cluster.capi_providers.(infra|bootstrap)_provider` are set to relevant values
# - `cluster.capo` for Openstack settings needed by cinder-csi
# - etc.
# any settings at the root of values, or under 'cluster', which is
# needed for any unit listed below, will have to be specified

unit_kustomization_spec_default:
  targetNamespace: '{{ .Release.Namespace }}'
  # ensure that our unit Kustomizations are deployed
  # in the workload cluster
  kubeConfig:
    secretRef:
      name: '{{ .Values.cluster.name }}-kubeconfig'

# for units that rely on Helm, the Kustomization will
# produce a HelmRelease which needs to be in the mgmt cluster
# so we "reset" the kubeconfig set right above
# (more below ...)
unit_helmrelease_kustomization_spec_default:
  kubeConfig: ~

# ... and its at the level of the HelmRelease that we ensure
# that the Helm release is deployed in the workload cluster
unit_helmrelease_spec_default:
  kubeConfig:
    secretRef:
      name: '{{ .Values.cluster.name }}-kubeconfig'
  targetNamespace: default  # so that units not having a targetNamespace are deployed in remote ns 'default' and not 'workload-cluster'


# here we select which units we want to enable for a workload cluster
units:

  cluster:
    enabled: true
    depends_on:
      # contrarily to what we have in default values, we don't
      # depend on capi-related units (CAPI is not deployed in the workload cluster)
      capi: false
      '{{ .Values.cluster.capi_providers.infra_provider }}': false
      '{{ .Values.cluster.capi_providers.bootstrap_provider }}': false
      # we don't depend on capo-cluster-resources, because
      # we define those resources outside of the workload-cluster sylva-units
      # Helm release
      capo-cluster-resources: false
    kustomization_spec:
      kubeConfig: ~  # because this resource lives in the mgmt cluster
    # helmrelease_spec:  ## to use when we'll switch to sylva-capi-cluster
    #   kubeConfig: ~  # because this resource lives in the mgmt cluster

  namespace-defs:
    enabled: true
    depends_on:
      cluster: true
    kustomization_spec:
      targetNamespace: ~  # if we don't do this, there are errors, presumably because namespaces are a non-namespaced resource

  calico-crd:
    enabled: true
    depends_on:
      namespace-defs: true
      cluster: true

  calico:
    enabled: true
    depends_on:
      namespace-defs: true
      cluster: true

  monitoring-crd:
    enabled: true
    depends_on:
      cluster: true
      calico: '{{ tuple . "calico" | include "unit-enabled" }}'

  monitoring:
    enabled: true
    depends_on:
      cluster: true
      calico: '{{ tuple . "calico" | include "unit-enabled" }}'

  multus:
    # can be enabled at runtime if desired:
    #enabled: true
    depends_on:
      cluster: true
      calico: '{{ tuple . "calico" | include "unit-enabled" }}'
