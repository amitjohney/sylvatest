# -- Insecure flag for secure/insecure connection to vSphere
insecure: true

# -- Labels to add to all objects generated by this chart
commonLabels: {}
# -- Annotations to add to all objects generated by this chart
commonAnnotations: {}


wait:
  # -- Deploy a job waiting for machines to rollout after deployment
  cluster: false
  # -- Deploy a job waiting for apiServer to be available
  apiServer: false
  # -- max time waiting for resources to rollout
  timeout: 900


cluster:
  # -- Cluster name. If unset, the release name will be used
  name: ""
  controlPlaneEndpoint:
    # -- IP or DNS name of the kubernetes endpoint
    host: ""
    # -- Kubernetes endpoint port
    port: 6443
    # -- Linux interface on the node
    interface: ""
  # -- Network CIDR for pods
  podCidrBlocks:
    - 192.168.0.0/18
  # -- Network CIDR for services
  servicesCidrBlocks:
    - 10.96.0.0/12
  # -- Additionnal ClusterResource to add to ClusterResourceSet
  additionalClusterResourceSet: []


kubernetes:
  # -- Version of kubernetes
  version: v1.22.8
  # -- Pem encoded certificate to authenticate clients over x509
  additionnalClientCaFile: ""
  kubeadm:
    # -- Additional kubelet command line arguments for init and join configurations
    commonKubeletExtraArgs: {}
    controlPlane:
      # -- Kubeadm cluster configuration, more info : https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/
      clusterConfiguration: {}
      # -- Additional files to create on the kubeadm control plane instances
      additionalFiles: []
      # -- Additional commands to execute on control plane before kubeadm join/init
      preKubeadmAdditionalCommands: []
      # -- Additional commands to execute on control plane after kubeadm join/init
      postKubeadmAdditionalCommands: []
      # -- Directory containing kubeadm patches on target vms
      patchesDirectory: ""
    workers:
      # -- files to create on the workers instances
      files: []
      # -- Additional commands to execute on workers before kubeadm join/init
      preKubeadmAdditionalCommands: []
      # -- Additional commands to execute on workers after kubeadm join/init
      postKubeadmAdditionalCommands: []


# Vsphere VMs configuration
machines:
  # -- Use dhcp for ipv4 configuration
  dhcp4: true
  # -- Nameservers for VMs DNS resolution
  nameServers: []
  # -- Search domains suffixes to configure on VMs
  searchDomains: []
  # -- VM network domain
  domain: ""
  # -- IPv4 gateway
  gateway: ""

  # -- users to create on machines
  # see https://github.com/kubernetes-sigs/cluster-api/blob/main/bootstrap/kubeadm/api/v1beta1/kubeadmconfig_types.go#L257 for documentation about user config object
  users: []

  # Control plane VMs configuration
  controlPlane:
    # -- Control plane VsphereMachineTemplate annotations
    annotations: {}
    # -- Number of control plane VMs instances
    replicas: 3
    # -- kube-vip version
    kubeVipVersion: v0.4.2
    # -- ipaddrs passed to capi if necessary
    ipAddrs: []
    # -- Path of the CRI socket to use
    criSocket: "/var/run/containerd/containerd.sock"
    # -- Control plane VSphere resource pool
    resourcePool: ""
    # -- Control plane VSphere machine template to clone, must contain kubeadm at the same version as specified in kubernetes.version
    template: ""
    # -- Control plane VSphere folder to store VM
    folder: ""
    # -- Control plane VSphere storage policy name to use for disks
    storagePolicy: ""
    # -- Control plane VSphere datastore to create/locate machine
    dataStore: ""
    # -- Control plane Number of vCPUs to allocate to controlPlane instances
    cpuCount: 2
    # -- Control plane Disk size of VM in GiB
    diskSizeGiB: 40
    # -- Control plane Memory to allocate to controlPlane VMs
    memorySizeMiB: 4096
    # -- Additional kubelet command line arguments for join configurations
    kubeletExtraArgs: {}
    # -- Node drain timeout is the total amount of time that the controller will spend on draining a node
    nodeDrainTimeout: ""
    machineHealthCheck:
      # -- Deploys a machineHealthCheck object for the controlPlane
      enabled: false
      # -- Any further remediation is only allowed if at most "MaxUnhealthy" machines are not healthy
      maxUnhealthy: 100%
      # -- Machines older than this duration without a node will be considered to have failed and will be remediated
      nodeStartupTimeout: ""
      # -- list of the conditions that determine whether a node is considered unhealthy. if any of the conditions is met, the node is unhealthy.
      unhealthyConditions:
        - type: Ready
          status: Unknown
          timeout: 300s
        - type: Ready
          status: "False"
          timeout: 300s
      # -- remediation is only allowed if the number of machines selected by "selector" as not healthy is within the range of "UnhealthyRange"
      unhealthyRange: ""

  # -- Worker pools, more details on its configuration in [Worker pools configuration](#worker-pools-configuration)
  workers: {}
    # # -- Name of the standard worker pool, you can define as many others pools as required
    # worker-md-0:
    #   # -- Number of worker VMs instances
    #   replicas: 1
    #   # -- MachineDeployment annotations
    #   machineDeploymentAnnotations: {}
    #   # -- Labels to add to the machines created by the machineDeployment
    #   machinesLabels: {}
    #   # -- Labels to add to the machineDeployment selector to match the machines
    #   machinesSelectors: {}
    #   # -- workers VsphereMachineTemplate annotations
    #   annotations: {}
    #   # -- ipaddrs passed to capi if necessary
    #   ipAddrs: []
    #   # -- Path of the CRI socket to use
    #   criSocket: "/var/run/containerd/containerd.sock"
    #   # -- workers VSphere resource pool
    #   resourcePool: ""
    #   # -- workers VSphere machine template to clone, must contain kubeadm at the same version as specified in kubernetes.version
    #   template: ""
    #   # -- workers VSphere folder to store VM
    #   folder: ""
    #   # -- workers VSphere storage policy name to use for disks
    #   storagePolicy: ""
    #   # -- workers VSphere datastore to create/locate machine
    #   dataStore: ""
    #   # -- Number of vCPUs to allocate to worker instances
    #   cpuCount: 4
    #   # -- disk size of workers VM in GiB
    #   diskSizeGiB: 100
    #   # -- Memory to allocate to worker VMs
    #   memorySizeMiB: 8192
    #   # -- files to create on the workers instances of this pool
    #   files: []
    #   # -- Additional commands to execute on workers before kubeadm join/init on this pool
    #   preKubeadmAdditionalCommands: []
    #   # -- Additional kubelet command line arguments for join configurations
    #   kubeletExtraArgs: {}
    #   # -- Node drain timeout is the total amount of time that the controller will spend on draining a node
    #   nodeDrainTimeout: ""
    #   machineHealthCheck:
    #     # -- Deploys a machineHealthCheck object for the workerPool
    #     enabled: false
    #     # -- Any further remediation is only allowed if at most "MaxUnhealthy" machines are not healthy
    #     maxUnhealthy: ""
    #     # -- Machines older than this duration without a node will be considered to have failed and will be remediated
    #     nodeStartupTimeout: ""
    #     # -- list of the conditions that determine whether a node is considered unhealthy. if any of the conditions is met, the node is unhealthy.
    #     unhealthyConditions:
    #     - type: Ready
    #       status: Unknown
    #       timeout: 300s
    #     - type: Ready
    #       status: "False"
    #       timeout: 300s
    #     # -- remediation is only allowed if the number of machines selected by "selector" as not healthy is within the range of "UnhealthyRange"
    #     unhealthyRange: ""


# Vsphere common configuration
vsphere:
  # -- Datacenter to use
  dataCenter: ""
  # -- VSphere network for VMs and CSI
  network: ""
  # -- Vsphere username
  username: ""
  # -- VSphere password
  password: ""
  # -- VSphere server dns name
  server: ""
  # -- VSphere https TLS thumbprint
  tlsThumbprint: ""



vsphereCsi:
  # -- Installs vsphere-csi on the cluster
  enabled: true

  cloudControllerManager:
    # -- resources of vsphere-cloud-controller-manager
    resources:
      requests:
        cpu: 200m

  controller:
    csiAttacher:
      # -- resources of the container csi-attacher in vsphere-csi-controller
      resources: {}
      #
#    csiResizer:
#      # -- resources of the container csi-resizer in vsphere-csi-controller
#      resources: {}
#      #
    vsphereCsiController:
      # -- resources of the container vsphere-csi-controller in vsphere-csi-controller
      resources: {}
      #
    vsphereSyncer:
      # -- resources of the container vsphere-syncer in vsphere-csi-controller
      resources: {}
      #
    csiProvisioner:
      # -- resources of the container csi-provisioner in vsphere-csi-controller
      resources: {}
      #
#    csiSnapshotter:
#      # -- resources of the container csi-snapshotter in vsphere-csi-controller
#      resources: {}
#      #
    livenessProbe:
      # -- resources of the container liveness-probe in vsphere-csi-controller
      resources: {}
      #

  node:
    nodeDriverRegistrar:
      # -- resources of the container node-driver-registrar in vsphere-csi-node
      resources: {}
    vsphereCsiNode:
      # -- resources of the container vsphere-csi-node in vsphere-csi-node
      resources: {}
    livenessProbe:
      # -- resources of the container liveness-probe in vsphere-csi-node
      resources: {}

# Storage class configuration
storageClass:
  # -- Create storage class
  enabled: false
  # -- Storage class name
  name: "default"
  # -- Define storage class as default class
  default: true
  # -- Storage class reclaimPolicy
  reclaimPolicy: "Delete"
  # -- Storage class fsType
  fsType: ext4
  # -- VSphere Storage policy
  storagePolicy: ""

cni:
  calico:
    # -- Installs cni calico on the cluster
    enabled: false


