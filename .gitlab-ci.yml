
workflow:
  rules:
    # prevent branch pipeline when an MR is open (prefer MR pipeline)
    - if: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS'
      when: never
    - when: always

stages:
  - test
  - build
  - deploy
  - deployment-test
  - delete

default:
  tags:
    - gitlab-org-docker
  image: $CI_IMAGE

variables:
  DOCKER_TLS_CERTDIR: ""
  GITLEAKS_ARGS: '--verbose --log-opts=$CI_COMMIT_SHA'
  DOCKER_HOST: tcp://docker:2375/
  CAPO_PLATFORM_TAG: capo-ci
  OCI_TAG_FORMAT: "0.0.0-git-$CI_COMMIT_SHORT_SHA"
  # renovate: datasource=docker
  CI_IMAGE: registry.gitlab.com/sylva-projects/sylva-elements/container-images/ci-image:v1.0.8
  # renovate: datasource=docker
  OPENSTACK_CLIENT_IMAGE: registry.gitlab.com/sylva-projects/sylva-elements/container-images/openstack-client:v0.0.5

include:
  - project: "to-be-continuous/gitleaks"
    ref: 2.2.2
    file: "templates/gitlab-ci-gitleaks.yml"
  - project: 'renovate-bot/renovate-runner'
    ref: v15.57.3
    file: '/templates/renovate-config-validator.gitlab-ci.yml'
    rules:
      - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
        changes:
          paths:
            - .gitlab-ci.yml
            - renovate.json
  - project: 'sylva-projects/sylva-elements/renovate'
    ref: 1.0.0
    file: '/templates/renovate-dry-run.gitlab-ci.yml'
    rules:
      - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
        changes:
          paths:
            - renovate.json

.generator-base:
  stage: test
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - charts/**/*
        - kustomize-units/**/*
        - environment-values/**/*
        - tools/gci-templates/**/*
        - tools/generate_json_schema.py

chart-generator:
  extends: .generator-base
  script:
    - echo "Generate CI jobs for each modified charts/units/environment-values"
    - ./tools/gci-templates/scripts/generate-pipeline.sh > generated-pipeline.yml
  artifacts:
    expire_in: 1 hour
    paths:
      - generated-pipeline.yml

chart-jobs:
  extends: .generator-base
  needs:
    - chart-generator
  trigger:
    include:
      - artifact: generated-pipeline.yml
        job: chart-generator
    strategy: depend

.lint-base:
  stage: test
  needs: []
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'

yamllint:
  extends: .lint-base
  script:
    - 'yamllint . -d "$(cat < tools/gci-templates/configuration/yamllint.yaml) $(cat < tools/gci-templates/configuration/yamllint-helm-exclude-charts.yaml)"'

avoid-typo-on-bootstrap:
  extends: .lint-base
  script:
    - |
      rm -rf .git  # because busybox grep does not support --exclude-dir
      echo "Check against frequent typos on 'bootstrap'..."
      set +e
      typos=$(grep -rnsiE 'boostrap|bootrap|bootsrap' . | grep -v '.gitlab-ci.yaml:      typos=')
      set -e
      if [ -n "$typos" ]; then
        echo "A few typos were found on the 'bootstrap' word:"
        echo "-----------------"
        echo "$typos"
        echo "-----------------"
        exit 1
      fi

flux-check-versions:
   # this job checks that the different versions of Flux that we use are aligned:
   # - flux binary in sylva-toolbox
   # - flux kustomization (kustomize-units/flux-system)

  extends: .lint-base
  services:
    - name: docker:23.0.6-dind
      alias: docker
  script:
    - eval $(grep ^SYLVA_TOOLBOX_ tools/shell-lib/common.sh)
    - mkdir bin
    - docker run --rm ${SYLVA_TOOLBOX_REGISTRY}/${SYLVA_TOOLBOX_IMAGE}:${SYLVA_TOOLBOX_VERSION} | tar xz -C bin
    - binary_version=$(bin/flux version --client -o yaml | yq .flux)
    - kustomization_version=$(yq '.resources[0] | capture("/(?P<version>v[^/]+)/") | .version' kustomize-units/flux-system/base/kustomization.yaml)
    - |
      if [[ $binary_version != $kustomization_version ]]; then
        echo
        echo "Flux version mismatch between the 'flux' binary provided in sylva-toolbox and the Flux version used in kustomize-units/flux-system"
        echo "- flux binary has version $binary_version"
        echo "- flux kustomization has  $kustomization_version"
        exit -1
        echo
      fi

check-docs-markdown:
  extends: .lint-base
  image: registry.gitlab.com/gitlab-org/gitlab-docs/lint-markdown:alpine-3.16-vale-2.20.2-markdownlint-0.32.2-markdownlint2-0.5.1
  script:
    - git fetch origin $CI_MERGE_REQUEST_TARGET_BRANCH_NAME
    - |
      md_files=$(git diff --name-only $CI_COMMIT_SHA origin/$CI_MERGE_REQUEST_TARGET_BRANCH_NAME | grep "\.md$" || true)
      if [ -n "$md_files" ] ; then
        markdownlint-cli2-config tools/gci-templates/configuration/.markdownlint.yml $md_files
      else
        echo "No modified .md files"
      fi
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
      changes:
        - "**/*.md"

.deploy-base:
  stage: deploy
  services:
    - name: docker:23.0.6-dind
      alias: docker
  artifacts:
    expire_in: 6 hour
    when: always
    paths:
      - debug-on-exit.log
      - bootstrap-cluster-dump/
      - management-cluster-dump/
      - bootstrap-cluster-units-report.xml
      - management-cluster-units-report.xml
      - bootstrap-timeline.html
      - management-cluster-timeline.html
      - management-cluster-kubeconfig
    reports:
      junit:
      - bootstrap-cluster-units-report.xml
      - management-cluster-units-report.xml
  needs:
    - job: push-helm-artifacts
      optional: true
    - job: publish-kustomize-units-artifact
      optional: true
    - job: publish-sylva-units-artifact
      optional: true

.common-deployment:
  script_common:
    - echo -e "\e[1m\e[0Ksection_start:`date +%s`:gitlab_ci_common[collapsed=true]\r\e[0KRunning common deployment steps\e[0m"
    - export DOCKER_IP=$(getent ahostsv4 docker | awk '{print $1}' | sort -u)
    - export ENV_PATH=environment-values/${ENV_NAME}
    - values_file=environment-values/${ENV_NAME}/values.yaml
    - docker network create --attachable kind
    - KIND_PREFIX=$(docker network inspect kind -f '{{ (index .IPAM.Config 0).Subnet }}')
    - ip route add $KIND_PREFIX via $DOCKER_IP
    - export KIND_CLUSTER_NAME=bootstrap-${CI_PIPELINE_ID}-${ENV_NAME}
    - export MANAGEMENT_CLUSTER_NAME="management-cluster-${CI_PIPELINE_ID}-${ENV_NAME}"
    - export TEST_WORKLOAD_CLUSTER_NAME="first-workload-cluster-${CI_PIPELINE_ID}-${ENV_NAME}"
    - |
      if [ ${OCI_TAG} ]; then
        echo -e "Applying OCI configuration for tag: ${OCI_TAG}"
        export KIND_CLUSTER_NAME="bootstrap-${CI_PIPELINE_ID}-${ENV_NAME}-oci"
        export MANAGEMENT_CLUSTER_NAME="management-cluster-${CI_PIPELINE_ID}-${ENV_NAME}-oci"
        export TEST_WORKLOAD_CLUSTER_NAME="first-workload-cluster-${CI_PIPELINE_ID}-${ENV_NAME}-oci"
        if [ $(yq '.components | length' environment-values/$ENV_NAME/kustomization.yaml) -eq "0" ]; then yq -i '.components = []' environment-values/$ENV_NAME/kustomization.yaml; fi
        yq -i '.components += "../components/oci-artifacts"' $ENV_PATH/kustomization.yaml
      cat <<EOF>> $ENV_PATH/kustomization.yaml
      patches:
      - target:
          kind: HelmRelease
          name: sylva-units
        patch: |
          - op: replace
            path: /spec/chart/spec/version
            value: ${OCI_TAG}
      EOF
        cat $ENV_PATH/kustomization.yaml
        export METALLB_HELM_OCI_URL='{{ lookup "source.toolkit.fluxcd.io/v1beta2" "HelmRepository" "default" "sylva-core" | dig "spec" "url" "oci://registry.gitlab.com/sylva-projects/sylva-core" | dir | replace "oci:/" "oci://" }}/sylva-core/metallb'
        yq -i '.metallb_helm_oci_url = strenv(METALLB_HELM_OCI_URL)' $values_file
      fi
    - yq -i '.cluster.name = strenv(MANAGEMENT_CLUSTER_NAME)' $values_file
    - yq -i '.cluster.test_workload_cluster_name = strenv(TEST_WORKLOAD_CLUSTER_NAME)' $values_file
    - yq -i '.env_type = "ci"' $values_file
    - |
      if [ ${CUSTOM_VALUES_FILE} ]; then
        yq -i eval-all '. as $item ireduce ({}; . * $item )' $values_file $CUSTOM_VALUES_FILE
      fi
    - echo -e "\e[0Ksection_end:`date +%s`:gitlab_ci_common\r\e[0K"
  script_capd:
    - echo -e "\e[1m\e[0Ksection_start:`date +%s`:gitlab_ci_capd[collapsed=true]\r\e[0KApplying specific capd configuration\e[0m"
    - export DOCKER_HOST=tcp://$DOCKER_IP:2375
    - yq -i '.cluster.capd.docker_host = strenv(DOCKER_HOST)' $values_file
    - export CLUSTER_EXTERNAL_IP=$(echo $KIND_PREFIX | awk -F"." '{print $1"."$2"."$3".100"}')
    - yq -i '.cluster.cluster_external_ip = strenv(CLUSTER_EXTERNAL_IP)' $values_file
    - echo -e "\e[0Ksection_end:`date +%s`:gitlab_ci_capd\r\e[0K"
  script_capo:
    - echo -e "\e[1m\e[0Ksection_start:`date +%s`:gitlab_ci_capo[collapsed=true]\r\e[0KApplying specific capo configuration\e[0m"
    - yq -i eval-all 'select(fileIndex==0).cluster.capo.clouds_yaml = select(fileIndex==1) | select(fileIndex==0)' environment-values/${ENV_NAME}/secrets.yaml ~/.config/openstack/clouds.yml
    - echo "CAPO_TAG=${CAPO_TAG}"
    - export CAPO_TAG="${CAPO_TAG}"
    - yq -i '.cluster.capo.resources_tag = strenv(CAPO_TAG)' $values_file
    - git config --global credential.helper cache
    # the CI_COMPONENT_* variables below are set in the gitlab runner configuration
    # and allow to enable extra kustomize components needed in the context of the platform
    # on which this test actually runs
    - git clone --depth=1 https://foo:${CI_COMPONENT_REPO_PAT}@${CI_COMPONENT_REPO}
    - export CI_COMPONENT="https://${CI_COMPONENT_REPO}//${CI_COMPONENT_REPO_PATH}-${ENV_NAME}?ref=2023-07-11"
    - if [ $(yq '.components | length' environment-values/$ENV_NAME/kustomization.yaml) -eq "0" ]; then yq -i '.components = []' environment-values/$ENV_NAME/kustomization.yaml; fi
    - yq -i '.components += strenv(CI_COMPONENT)' environment-values/$ENV_NAME/kustomization.yaml
    - yq -e '.registry_mirrors' $(basename ${CI_COMPONENT_REPO} .git)/${CI_COMPONENT_REPO_PATH}-base/values.yaml > registry_mirrors.yml
    - yq -i eval-all 'select(fileIndex==0).registry_mirrors = select(fileIndex==1) | select(fileIndex==0)' $values_file registry_mirrors.yml
    - echo -e "\e[0Ksection_end:`date +%s`:gitlab_ci_capo\r\e[0K"
  post_deployment_common:
    - export CHECK_RANCHER_JOB_POD=`kubectl --kubeconfig management-cluster-kubeconfig -n kube-job get pod --selector job-name=check-rancher-clusters-job-cattle-system -o=jsonpath='{.items[?(@.status.phase=="Succeeded")].metadata.name}'`
    - kubectl --kubeconfig management-cluster-kubeconfig -n kube-jobs logs $CHECK_RANCHER_JOB_POD || echo "No workload clusters here"
  os_cloud:
    # the OS_* variables below are set in the gitlab runner configuration
    # and contain information to connect to the OpenStack instance used
    # by this test
    - mkdir -p ~/.config/openstack
    - |
      cat <<EOF>> ~/.config/openstack/clouds.yml
      clouds:
        capo_cloud:
          auth:
            auth_url: '${OS_AUTH_URL}'
            user_domain_name: '${OS_USER_DOMAIN_ID}'
            project_domain_name: '${OS_PROJECT_DOMAIN_ID}'
            project_name: '${OS_TENANT_NAME}'
            username: '${OS_USERNAME}'
            password: '${OS_PASSWORD}'
          region_name: '${OS_REGION_NAME}'
          verify: false
      EOF
  variables:
    # if a deploy job sets this to "even" (resp. "odd"), the job will automatically trigger
    # for any MR having an even MR number and the run-e2e-tests label
    E2E_JOB_MR_PARITY: any
  rules:
    - if: '$CI_COMMIT_TAG && $OCI_TAG'
      variables:
        OCI_TAG: $CI_COMMIT_TAG
    - if: $CI_PIPELINE_SOURCE == 'web'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_DEPLOYMENTS'
    - if: $CI_MERGE_REQUEST_LABELS =~ /run-e2e-tests/ && ($E2E_JOB_MR_PARITY == "any" || ($E2E_JOB_MR_PARITY == "even" && $CI_OPEN_MERGE_REQUESTS =~ /[02468]$/) || ($E2E_JOB_MR_PARITY == "odd" && $CI_OPEN_MERGE_REQUESTS =~ /[13579]$/))
      allow_failure: true
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
      allow_failure: true
      when: manual

deploy-preview-capd:
  extends: .deploy-base
  timeout: 15min
  script:
    - !reference [.common-deployment, script_common]
    - !reference [.common-deployment, script_capd]
    - ./preview.sh environment-values/${ENV_NAME}
  artifacts:
    when: on_failure
    expire_in: 1 hour
    paths:
      - debug-on-exit.log
      - bootstrap-cluster-dump/
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      changes:
        - preview.sh
        - tools/shell-lib/common.sh
  variables:
    ENV_NAME: kubeadm-capd

deploy-preview-capd-oci:
  extends: deploy-preview-capd
  variables:
    ENV_NAME: kubeadm-capd
    OCI_TAG: $OCI_TAG_FORMAT

deploy-kubeadm-capd:
  timeout: 60min
  extends: .deploy-base
  script:
    - !reference [.common-deployment, script_common]
    - !reference [.common-deployment, script_capd]
    - ./bootstrap.sh environment-values/${ENV_NAME}
    - !reference [.common-deployment, post_deployment_common]
  rules:
    - !reference [.common-deployment, rules]
  variables:
    ENV_NAME: kubeadm-capd
    E2E_JOB_MR_PARITY: even
  artifacts:
    expose_as: kubeadm-capd

deploy-kubeadm-capd-oci:
  extends: deploy-kubeadm-capd
  variables:
    ENV_NAME: kubeadm-capd
    OCI_TAG: $OCI_TAG_FORMAT
    E2E_JOB_MR_PARITY: odd
  artifacts:
    expose_as: kubeadm-capd-oci

.deploy-capo:
  extends: .deploy-base
  script:
    - !reference [.common-deployment, script_common]
    - !reference [.common-deployment, os_cloud]
    - !reference [.common-deployment, script_capo]
    - ./bootstrap.sh environment-values/${ENV_NAME}
    - !reference [.common-deployment, post_deployment_common]
  rules:
    - if: $CI_MERGE_REQUEST_LABELS =~ /renovate/
      allow_failure: true
      when: manual
    - !reference [.common-deployment, rules]
  tags:
    - $CAPO_PLATFORM_TAG

deploy-rke2-capo:
  timeout: 60min
  extends: .deploy-capo
  variables:
    ENV_NAME: "rke2-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}"
    E2E_JOB_MR_PARITY: odd
  artifacts:
    expose_as: rke2-capo

deploy-rke2-capo-oci:
  extends: deploy-rke2-capo
  variables:
    ENV_NAME: "rke2-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}-OCI"
    OCI_TAG: $OCI_TAG_FORMAT
    E2E_JOB_MR_PARITY: even
  artifacts:
    expose_as: rke2-capo-oci

deploy-kubeadm-capo:
  timeout: 55min
  extends: .deploy-capo
  variables:
    ENV_NAME: "kubeadm-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}"
    E2E_JOB_MR_PARITY: even
  artifacts:
    expose_as: kubeadm-capo

deploy-kubeadm-capo-oci:
  extends: deploy-kubeadm-capo
  variables:
    ENV_NAME: "kubeadm-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}-OCI"
    OCI_TAG: $OCI_TAG_FORMAT
    E2E_JOB_MR_PARITY: odd
  artifacts:
    expose_as: kubeadm-capo-oci

deploy-m3-units-in-capo:
  timeout: 35min
  extends: deploy-kubeadm-capo
  variables:
    ENV_NAME: "kubeadm-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}-M3-OCI"
    OCI_TAG: $OCI_TAG_FORMAT
    CUSTOM_VALUES_FILE: environment-values/ci/m3-units-in-capo.yml
    MGMT_WATCH_TIMEOUT_MIN: 20
  artifacts:
    expose_as: m3-units-in-capo

deploy-capo-fip:
  timeout: 35min
  extends: deploy-kubeadm-capo
  variables:
    ENV_NAME: "kubeadm-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}-FIP"
    OCI_TAG: $OCI_TAG_FORMAT
    CUSTOM_VALUES_FILE: environment-values/ci/capo-fip.yml
    MGMT_WATCH_TIMEOUT_MIN: 20
  artifacts:
    expose_as: capo-fip
  rules:
    - if: $CI_MERGE_REQUEST_LABELS =~ /renovate/
      allow_failure: true
      when: manual
    - if: '$CI_COMMIT_TAG && $OCI_TAG'
      variables:
        OCI_TAG: $CI_COMMIT_TAG
    - if: $CI_PIPELINE_SOURCE == 'web'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_DEPLOYMENTS'
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
      allow_failure: true
      when: manual

.script-test-workload-cluster: |
  set -e
  set -o pipefail
  echo "-- Get secret workoad-cluster-rancher-kubeconfig and save it locally in a workload-cluster-rancher-kubeconfig file"
  kubectl --kubeconfig management-cluster-kubeconfig -n cattle-system get secret workload-cluster-rancher-kubeconfig -o jsonpath='{.data.kubeconfig}' | base64 -d | yq -P > workload-cluster-rancher-kubeconfig
  echo "-- Get ingress saved into /etc/hosts"
  kubectl --kubeconfig management-cluster-kubeconfig get ingress -A -o custom-columns=:.status.loadBalancer.ingress[].ip,:.spec.tls[].hosts[] | grep -v '<none>' >> /etc/hosts
  export no_proxy=$no_proxy,.sylva
  attempts=0
  max_attempts=5
  until kubectl run test --image=busybox --kubeconfig workload-cluster-rancher-kubeconfig -- sleep 10; do
    sleep 3
    ((attempts++)) && ((attempts==max_attempts)) && exit -1
  done
  echo "-- Wait for test pod to be created"
  kubectl wait --for=condition=Ready pod/test --kubeconfig workload-cluster-rancher-kubeconfig --timeout=60s
  echo "-- All done"

.testing-workload-cluster:
  stage: deployment-test
  rules:
    - if: '$CI_COMMIT_TAG && $OCI_TAG'
    - if: $CI_PIPELINE_SOURCE == 'web'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_DEPLOYMENTS'
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
  allow_failure: true
  script:
    - echo "Testing workload cluster. Job started at '$CI_JOB_STARTED_AT'."
    - !reference [.script-test-workload-cluster]
  tags:
    - $CAPO_PLATFORM_TAG

testing-workload-cluster-rke2-capo:
  extends: .testing-workload-cluster
  variables:
    ENV_DEPLOY_JOB: "deploy-rke2-capo"
  needs:
    - deploy-rke2-capo

testing-workload-cluster-rke2-capo-oci:
  extends: .testing-workload-cluster
  variables:
    ENV_DEPLOY_JOB: "deploy-rke2-capo-oci"
  needs:
    - deploy-rke2-capo-oci

testing-workload-cluster-kubeadm-capo:
  extends: .testing-workload-cluster
  variables:
    ENV_DEPLOY_JOB: "deploy-kubeadm-capo"
  needs:
    - deploy-kubeadm-capo

testing-workload-cluster-kubeadm-capo-oci:
  extends: .testing-workload-cluster
  variables:
    ENV_DEPLOY_JOB: "deploy-kubeadm-capo-oci"
  needs:
    - deploy-kubeadm-capo-oci

.cleanup-capo:
  stage: delete
  image:
    name: $OPENSTACK_CLIENT_IMAGE
  script:
    - !reference [.common-deployment, os_cloud]
    - ./tools/openstack-cleanup.sh capo_cloud "${CAPO_TAG}"
  rules:
    - if: '$CI_COMMIT_TAG && $OCI_TAG'
    - if: $CI_PIPELINE_SOURCE == 'web'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_DEPLOYMENTS'
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
  allow_failure: true
  tags:
    - $CAPO_PLATFORM_TAG

cleanup-rke2-capo:
  extends: .cleanup-capo
  variables:
    ENV_NAME: "rke2-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}"
  needs:
    - testing-workload-cluster-rke2-capo

cleanup-kubeadm-capo:
  extends: .cleanup-capo
  variables:
    ENV_NAME: "kubeadm-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}"
  needs:
    - testing-workload-cluster-kubeadm-capo

cleanup-rke2-capo-oci:
  extends: .cleanup-capo
  variables:
    ENV_NAME: "rke2-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}-OCI"
    OCI_TAG: $OCI_TAG_FORMAT # required to match the same rules as OCI based deployments
  needs:
    - testing-workload-cluster-rke2-capo-oci

cleanup-kubeadm-capo-oci:
  extends: .cleanup-capo
  variables:
    ENV_NAME: "kubeadm-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}-OCI"
    OCI_TAG: $OCI_TAG_FORMAT # required to match the same rules as OCI based deployments
  needs:
    - testing-workload-cluster-kubeadm-capo-oci

cleanup-m3-units-in-capo:
  extends: .cleanup-capo
  variables:
    ENV_NAME: "kubeadm-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}-M3-OCI"
    OCI_TAG: $OCI_TAG_FORMAT # required to match the same rules as OCI based deployments
  needs:
    - deploy-m3-units-in-capo

cleanup-capo-fip:
  extends: .cleanup-capo
  variables:
    ENV_NAME: "kubeadm-capo"
    CAPO_TAG: "${CI_PIPELINE_ID}-${ENV_NAME}-FIP"
    OCI_TAG: $OCI_TAG_FORMAT # required to match the same rules as OCI based deployments
  needs:
    - deploy-capo-fip

scheduled-cleanup-capo:
  stage: delete
  image:
    name: $OPENSTACK_CLIENT_IMAGE
  script:
    - !reference [.common-deployment, os_cloud]
    - touch tags.txt exclude-tags.txt
    - MAX_DEPLOY_CAPO_TIMEOUT=$(yq .deploy-*-capo.timeout .gitlab-ci.yml | awk -F"min" '{print $1}' | sort -nr | head -1)
    - STACK_TTL=$(((MAX_DEPLOY_CAPO_TIMEOUT+5)*60))
    - |
      for STACK in $(openstack stack list -f value -c "Stack Name" | grep -E '^(management|workload|capo)-cluster' ); do
        STACK_TIME=$(date -d "$(openstack stack show ${STACK} -c creation_time -f value | tr T ' ' | tr -d Z )" +%s)
        THIS_TIME=$(date +%s)
        # we'll only consider for cleanup tags applied to resources created more than STACK_TTL seconds ago
        if [ $((THIS_TIME-STACK_TIME)) -gt ${STACK_TTL} ]; then
            # and we'll delay the cleanup for tags of stacks where second tag is "please-delay-cleanup"; patched with `openstack stack update --existing --tag sylva-foo.bar,please-delay-cleanup ${STACK}
            if openstack stack show ${STACK} -c tags -f json | jq .tags[] -r | grep -xq "please-delay-cleanup"; then
                # but only for an period of 12 hours after its creation
                if [ $((THIS_TIME-STACK_TIME)) -lt 43200 ]; then
                    echo -e "The cleanup of the $(openstack stack show ${STACK} -c tags -f json | jq .tags[0] -r) tag is delayed for $(((STACK_TIME+43200-THIS_TIME)/60)) minutes"
                    openstack stack show ${STACK} -c tags -f json | jq .tags[0] -r >> exclude-tags.txt
                fi
            fi
            openstack stack show ${STACK} -c tags -f json | jq .tags[] -r >> tags.txt
        else
            openstack stack show ${STACK} -c tags -f json | jq .tags[] -r >> exclude-tags.txt
        fi
      done
    - |
      # skip the cleanup for resources with tags present in exclude-tags.txt
      set +e
      echo "Remaining stacks:" > scheduled_cleanup_status
      for CAPO_TAG in $(comm -3 -2 <(sort tags.txt) <(sort exclude-tags.txt) | sort -u); do
        echo -e "\e[1m\e[0Ksection_start:`date +%s`:scheduled_cleanup[collapsed=true]\r\e[0K\U0001F5D1  Cleaning tag: ${CAPO_TAG} \e[0m"
        if ! ./tools/openstack-cleanup.sh capo_cloud ${CAPO_TAG}; then
          global_cleanup_status=1
          echo "Following stack(s) cleanup failed:" >> scheduled_cleanup_status
          openstack stack list --tags ${CAPO_TAG} >> scheduled_cleanup_status
        fi
        echo -e "\e[0Ksection_end:`date +%s`:scheduled_cleanup\r\e[0K"
      done
      set -e
      cat scheduled_cleanup_status || true
      exit ${global_cleanup_status-0}
  variables:
    OS_CLOUD: "capo_cloud"
  rules:
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_CAPO_CLEANUP'
      when: always
  tags:
    - $CAPO_PLATFORM_TAG

.build-base:
  stage: build
  dependencies: []
  variables:
    OCI_REGISTRY: oci://${CI_REGISTRY_IMAGE}
    OCI_TAG: $OCI_TAG_FORMAT
  rules:
    - if: $CI_COMMIT_TAG
      variables:
        OCI_TAG: $CI_COMMIT_TAG
    - if: $CI_PIPELINE_SOURCE == 'web'
    - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_DEPLOYMENTS'
    - if: $CI_MERGE_REQUEST_LABELS =~ /run-e2e-tests/
      allow_failure: true
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

publish-kustomize-units-artifact:
  extends: .build-base
  script:
    - tools/oci/build-kustomize-units-artifact.sh ${OCI_TAG}

push-helm-artifacts:
  extends: .build-base
  script:
    - tools/oci/push-helm-charts-artifacts.sh "oci://${CI_REGISTRY_IMAGE}"

publish-sylva-units-artifact:
  extends: .build-base
  script:
    - tools/oci/build-sylva-units-artifact.sh ${OCI_TAG}
